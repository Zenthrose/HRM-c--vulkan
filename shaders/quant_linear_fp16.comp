#version 450
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
// FP16 quantized linear layer compute shader
// Performs: output = input @ weights + bias (with FP16 precision)

layout(local_size_x = 64, local_size_y = 1, local_size_z = 1) in;

layout(binding = 0) readonly buffer InputBuffer {
    f16vec4 input_data[];  // FP16 input data (packed as vec4 for efficiency)
};

layout(binding = 1) readonly buffer WeightBuffer {
    f16vec4 quantized_weights[];  // FP16 weights
};

layout(binding = 2) readonly buffer BiasBuffer {
    float bias_data[];  // Bias in FP32 for accumulation
};

layout(binding = 3) writeonly buffer OutputBuffer {
    float output_data[];  // Output in FP32
};

// Push constants for layer dimensions
layout(push_constant) uniform PushConstants {
    uint input_size;      // Input feature dimension (must be multiple of 4)
    uint output_size;     // Output feature dimension
    uint batch_size;      // Number of input samples
} pc;

void main() {
    uint global_id = gl_GlobalInvocationID.x;
    uint total_threads = gl_WorkGroupSize.x * gl_NumWorkGroups.x;

    // Each thread processes one output element per batch
    for (uint batch_idx = 0; batch_idx < pc.batch_size; ++batch_idx) {
        for (uint out_idx = global_id; out_idx < pc.output_size; out_idx += total_threads) {
            f16 sum = f16(0.0f);

            // Perform matrix multiplication in FP16
            uint input_vecs = pc.input_size / 4;  // Assuming input_size is multiple of 4
            for (uint in_vec_idx = 0; in_vec_idx < input_vecs; ++in_vec_idx) {
                // Load input vector
                f16vec4 input_vec = input_data[batch_idx * input_vecs + in_vec_idx];

                // Load weight vector
                f16vec4 weight_vec = quantized_weights[out_idx * input_vecs + in_vec_idx];

                // Compute dot product
                sum += dot(input_vec, weight_vec);
            }

            // Handle remaining elements if input_size not multiple of 4
            uint remaining = pc.input_size % 4;
            if (remaining > 0) {
                uint base_idx = batch_idx * pc.input_size + input_vecs * 4;
                uint weight_base_idx = out_idx * pc.input_size + input_vecs * 4;

                for (uint i = 0; i < remaining; ++i) {
                    // Note: This simplified version assumes we can access individual elements
                    // In practice, we'd need to handle the packing more carefully
                    f16 input_val = f16(input_data[base_idx + i].x);  // Simplified access
                    f16 weight_val = f16(quantized_weights[weight_base_idx + i].x);  // Simplified access
                    sum += input_val * weight_val;
                }
            }

            // Convert to float, add bias, and write output
            uint output_idx = batch_idx * pc.output_size + out_idx;
            output_data[output_idx] = float(sum) + bias_data[out_idx];
        }
    }
}
